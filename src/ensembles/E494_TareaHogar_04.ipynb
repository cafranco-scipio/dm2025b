{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cEmzeUKFkPh"
      },
      "source": [
        "# Tarea para el Hogar 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSICPpyTGQmC"
      },
      "source": [
        "Esta Tarea para el Hogar 02 se entrega el final de la cuarta clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DenyKXkiJ5JN"
      },
      "source": [
        "##  1. Cazatalentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      },
      "source": [
        "En la Clase 03 nos hemos enfrentado a  \"La Maldicion del Ganandor\",  elegir el modelo con el mejor puntaje simple no suele ser la mejor estrategia.\n",
        "<br> Lea y ejecute el notebook  **src/CazaTalentos/CazaTalentos.ipynb**\n",
        "<br> en caso de interesarle, participe del Desafío Ordenamiento  que vence el sábado 06 de septiembre a las 19:00"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9GkTOk5J9t3"
      },
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmEFy0ukKL5T"
      },
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yvlS6JQLRMd"
      },
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydI4YNAsFaf"
      },
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzU4S0SeMcpp"
      },
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNptUgI_NWWG"
      },
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpUThBojODyK"
      },
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "outputId": "0c3b6aac-bdb2-473d-dd0c-7ed07b89c0cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/.drive\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "outputId": "00e12cac-1d58-4867-95d7-0700920e683b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/dm\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSKhZRToy2F7"
      },
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kwPpHAtSmix"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      },
      "source": [
        "### 2.2.1 Inicio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy8YTZfESxeJ"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBq__iAdQliq",
        "outputId": "ae1de7ce-a4bb-426f-96fd-cb003e261ea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Wed Sep 03 01:09:06 PM 2025'"
            ],
            "text/markdown": "'Wed Sep 03 01:09:06 PM 2025'",
            "text/latex": "'Wed Sep 03 01:09:06 PM 2025'",
            "text/plain": [
              "[1] \"Wed Sep 03 01:09:06 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7rdVrBojS1IV",
        "outputId": "0b391123-d679-4308-e139-42189e07acda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 659713</td><td>35.3</td><td>1454400</td><td>77.7</td><td>1433750</td><td>76.6</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1225810</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  659713 | 35.3 | 1454400 | 77.7 | 1433750 | 76.6 |\n| Vcells | 1225810 |  9.4 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  659713 & 35.3 & 1454400 & 77.7 & 1433750 & 76.6\\\\\n\tVcells & 1225810 &  9.4 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  659713 35.3 1454400    77.7 1433750  76.6\n",
              "Vcells 1225810  9.4 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      },
      "source": [
        "### 2.2.2 Carga de Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "outputId": "fb9997f2-7c1c-4b1f-9da8-bd3df7271e36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘primes’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘rlist’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘XML’\n",
            "\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: yaml\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘lightgbm’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘DiceKriging’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘mlrMBO’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘fastmatch’, ‘RcppArmadillo’, ‘mlr’, ‘ParamHelpers’, ‘smoof’, ‘BBmisc’, ‘checkmate’, ‘lhs’, ‘parallelMap’\n",
            "\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      },
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOdlKd7lUm2I"
      },
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ASYkebOu2mF6"
      },
      "outputs": [],
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5005\n",
        "PARAM$semilla_primigenia <- 600019\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ezOhQdbA293o"
      },
      "outputs": [],
      "source": [
        "PARAM$kaggle$competencia <- \"data-mining-analista-sr-2025-b\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jtB0Lub42rHO"
      },
      "outputs": [],
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OFxm-xiNUOJX"
      },
      "outputs": [],
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "# ================================\n",
        "# LightGBM + Bayesian Optimization\n",
        "# Opción 2 (intermedia, 40 iteraciones)\n",
        "# ================================\n",
        "\n",
        "# Cross-validation folds e iteraciones\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# ------------------------\n",
        "# Parámetros fijos\n",
        "# ------------------------\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  boosting= \"gbdt\",\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= FALSE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  force_row_wise= TRUE,\n",
        "  verbosity= -100,\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  max_depth= -1L,\n",
        "  min_gain_to_split= 0,\n",
        "  min_sum_hessian_in_leaf= 0.001,\n",
        "  lambda_l1= 0.0,\n",
        "  lambda_l2= 0.0,\n",
        "  max_bin= 31L,\n",
        "  bagging_fraction= 1.0,\n",
        "  pos_bagging_fraction= 1.0,\n",
        "  neg_bagging_fraction= 1.0,\n",
        "  is_unbalance= FALSE,\n",
        "  scale_pos_weight= 1.0,\n",
        "  drop_rate= 0.1,\n",
        "  max_drop= 50,\n",
        "  skip_drop= 0.5,\n",
        "  extra_trees= FALSE,\n",
        "  num_iterations= 1200,\n",
        "  learning_rate= 0.02,\n",
        "  feature_fraction= 0.5,\n",
        "  num_leaves= 750,\n",
        "  min_data_in_leaf= 5000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      },
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "<br> si es un numero entero debe ir  makeIntegerParam\n",
        "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
        "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jENpR26ZyuS8"
      },
      "outputs": [],
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeIntegerParam(\"num_leaves\",       lower = 64,   upper = 2048),\n",
        "  makeIntegerParam(\"max_depth\",        lower = 3,    upper = 15),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower = 200,  upper = 10000),\n",
        "  makeNumericParam(\"feature_fraction\", lower = 0.2,  upper = 1.0),\n",
        "  makeNumericParam(\"bagging_fraction\", lower = 0.2,  upper = 1.0),\n",
        "  makeNumericParam(\"learning_rate\",    lower = 0.005, upper = 0.1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_RPFUb3zMoW"
      },
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
        "<br> 30 es un valor muy tacaño, pero corre rápido\n",
        "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q5Rd3pnbzSiG"
      },
      "outputs": [],
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 60 # iteraciones bayesianas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RWZXL1VZjMI"
      },
      "source": [
        "### 2.2.4  Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j3toG9-lZm4K"
      },
      "outputs": [],
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FM3lxKoLZ643"
      },
      "outputs": [],
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OsJ-91UeZ-I_"
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vrWE7BE0aB2J"
      },
      "outputs": [],
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jP7YlQBnaW6W"
      },
      "outputs": [],
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xElu4s5W4rX7"
      },
      "outputs": [],
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PppMHcGYaaol",
        "outputId": "f0c82a52-54bd-4316-e8db-135d255abdc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "83587"
            ],
            "text/markdown": "83587",
            "text/latex": "83587",
            "text/plain": [
              "[1] 83587"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta-EkOu3cphF"
      },
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cjgfurjdfiXb"
      },
      "outputs": [],
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
        "    stratified= TRUE,\n",
        "    param= param_completo\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WLi_o1hocvN-"
      },
      "outputs": [],
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uUeVo5pc4zc"
      },
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RcABNaKGciaz",
        "outputId": "c1b4c9b5-b992-4aab-fa11-e1a6964c6ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "Wed Sep 03 01:29:15 PM 2025 AUC 0.924222882641643\n",
            "\n",
            "Wed Sep 03 01:31:29 PM 2025 AUC 0.926477024695584\n",
            "\n",
            "Wed Sep 03 01:35:24 PM 2025 AUC 0.925889433175454\n",
            "\n",
            "Wed Sep 03 01:39:08 PM 2025 AUC 0.926653948187577\n",
            "\n",
            "Wed Sep 03 01:43:12 PM 2025 AUC 0.924913512794421\n",
            "\n",
            "Wed Sep 03 01:47:10 PM 2025 AUC 0.92474441004962\n",
            "\n",
            "Wed Sep 03 01:50:16 PM 2025 AUC 0.922248291828781\n",
            "\n",
            "Wed Sep 03 01:54:55 PM 2025 AUC 0.926935662472243\n",
            "\n",
            "Wed Sep 03 01:56:57 PM 2025 AUC 0.924665712127406\n",
            "\n",
            "Wed Sep 03 01:59:21 PM 2025 AUC 0.925146196805312\n",
            "\n",
            "Wed Sep 03 02:02:41 PM 2025 AUC 0.928710664183046\n",
            "\n",
            "Wed Sep 03 02:07:08 PM 2025 AUC 0.924797216084033\n",
            "\n",
            "Wed Sep 03 02:10:07 PM 2025 AUC 0.92744990981239\n",
            "\n",
            "Wed Sep 03 02:12:27 PM 2025 AUC 0.927149506769999\n",
            "\n",
            "Wed Sep 03 02:14:49 PM 2025 AUC 0.924167620569477\n",
            "\n",
            "Wed Sep 03 02:16:56 PM 2025 AUC 0.925101250122204\n",
            "\n",
            "Wed Sep 03 02:18:57 PM 2025 AUC 0.926654327761957\n",
            "\n",
            "Wed Sep 03 02:22:10 PM 2025 AUC 0.928906875128192\n",
            "\n",
            "Wed Sep 03 02:25:55 PM 2025 AUC 0.929901532906659\n",
            "\n",
            "Wed Sep 03 02:29:41 PM 2025 AUC 0.925357219423525\n",
            "\n",
            "Wed Sep 03 02:32:48 PM 2025 AUC 0.927514827339552\n",
            "\n",
            "Wed Sep 03 02:36:09 PM 2025 AUC 0.925144291278924\n",
            "\n",
            "Wed Sep 03 02:40:27 PM 2025 AUC 0.92488214330387\n",
            "\n",
            "Wed Sep 03 02:42:18 PM 2025 AUC 0.924405310707046\n",
            "\n",
            "[mbo] 0: num_leaves=876; max_depth=8; min_data_in_leaf=8258; feature_fraction=0.355; bagging_fraction=0.75; learning_rate=0.0456 : y = 0.924 : 233.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1301; max_depth=4; min_data_in_leaf=3236; feature_fraction=0.823; bagging_fraction=0.595; learning_rate=0.0421 : y = 0.926 : 133.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=762; max_depth=13; min_data_in_leaf=6320; feature_fraction=0.564; bagging_fraction=0.649; learning_rate=0.0825 : y = 0.926 : 234.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1791; max_depth=9; min_data_in_leaf=4248; feature_fraction=0.587; bagging_fraction=0.881; learning_rate=0.0401 : y = 0.927 : 224.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=520; max_depth=10; min_data_in_leaf=4599; feature_fraction=0.393; bagging_fraction=0.415; learning_rate=0.00689 : y = 0.925 : 243.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=575; max_depth=7; min_data_in_leaf=6604; feature_fraction=0.403; bagging_fraction=0.483; learning_rate=0.0735 : y = 0.925 : 238.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=703; max_depth=4; min_data_in_leaf=7185; feature_fraction=0.243; bagging_fraction=0.459; learning_rate=0.0111 : y = 0.922 : 185.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1202; max_depth=10; min_data_in_leaf=3790; feature_fraction=0.504; bagging_fraction=0.618; learning_rate=0.0589 : y = 0.927 : 278.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=998; max_depth=14; min_data_in_leaf=9863; feature_fraction=0.902; bagging_fraction=0.834; learning_rate=0.089 : y = 0.925 : 122.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=445; max_depth=7; min_data_in_leaf=5813; feature_fraction=0.794; bagging_fraction=0.693; learning_rate=0.0213 : y = 0.925 : 144.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1414; max_depth=12; min_data_in_leaf=1877; feature_fraction=0.719; bagging_fraction=0.979; learning_rate=0.0606 : y = 0.929 : 199.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1657; max_depth=7; min_data_in_leaf=9033; feature_fraction=0.497; bagging_fraction=0.925; learning_rate=0.0651 : y = 0.925 : 266.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=919; max_depth=14; min_data_in_leaf=3048; feature_fraction=0.734; bagging_fraction=0.357; learning_rate=0.0136 : y = 0.927 : 179.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1977; max_depth=5; min_data_in_leaf=1490; feature_fraction=0.846; bagging_fraction=0.308; learning_rate=0.0844 : y = 0.927 : 139.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=193; max_depth=6; min_data_in_leaf=8617; feature_fraction=0.63; bagging_fraction=0.704; learning_rate=0.0955 : y = 0.924 : 142.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1809; max_depth=13; min_data_in_leaf=9286; feature_fraction=0.886; bagging_fraction=0.241; learning_rate=0.0784 : y = 0.925 : 127.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=71; max_depth=3; min_data_in_leaf=1383; feature_fraction=0.634; bagging_fraction=0.293; learning_rate=0.0267 : y = 0.927 : 121.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1101; max_depth=5; min_data_in_leaf=1004; feature_fraction=0.217; bagging_fraction=0.558; learning_rate=0.0544 : y = 0.929 : 193.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1556; max_depth=10; min_data_in_leaf=505; feature_fraction=0.965; bagging_fraction=0.83; learning_rate=0.0188 : y = 0.93 : 224.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=288; max_depth=12; min_data_in_leaf=5487; feature_fraction=0.331; bagging_fraction=0.768; learning_rate=0.0361 : y = 0.925 : 226.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=394; max_depth=11; min_data_in_leaf=2487; feature_fraction=0.988; bagging_fraction=0.369; learning_rate=0.0714 : y = 0.928 : 187.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1485; max_depth=15; min_data_in_leaf=6775; feature_fraction=0.273; bagging_fraction=0.215; learning_rate=0.0492 : y = 0.925 : 200.4 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1890; max_depth=15; min_data_in_leaf=5055; feature_fraction=0.464; bagging_fraction=0.965; learning_rate=0.0977 : y = 0.925 : 257.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: num_leaves=1378; max_depth=3; min_data_in_leaf=7679; feature_fraction=0.694; bagging_fraction=0.522; learning_rate=0.0314 : y = 0.924 : 111.4 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 02:47:48 PM 2025 AUC 0.928101867311844\n",
            "\n",
            "[mbo] 1: num_leaves=1241; max_depth=13; min_data_in_leaf=201; feature_fraction=0.625; bagging_fraction=0.741; learning_rate=0.0371 : y = 0.928 : 329.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 02:51:53 PM 2025 AUC 0.928911107586802\n",
            "\n",
            "[mbo] 2: num_leaves=1433; max_depth=9; min_data_in_leaf=478; feature_fraction=0.998; bagging_fraction=1; learning_rate=0.0166 : y = 0.929 : 244.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 02:56:03 PM 2025 AUC 0.929386156130758\n",
            "\n",
            "[mbo] 3: num_leaves=2045; max_depth=11; min_data_in_leaf=741; feature_fraction=0.932; bagging_fraction=0.694; learning_rate=0.0216 : y = 0.929 : 249.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 4 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 03:00:32 PM 2025 AUC 0.926993731119061\n",
            "\n",
            "[mbo] 4: num_leaves=1426; max_depth=11; min_data_in_leaf=200; feature_fraction=0.948; bagging_fraction=0.808; learning_rate=0.025 : y = 0.927 : 268.2 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:05:56 PM 2025 AUC 0.929556509892112\n",
            "\n",
            "[mbo] 5: num_leaves=1471; max_depth=11; min_data_in_leaf=544; feature_fraction=0.515; bagging_fraction=0.721; learning_rate=0.0375 : y = 0.93 : 322.8 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:08:48 PM 2025 AUC 0.929411353569984\n",
            "\n",
            "[mbo] 6: num_leaves=1174; max_depth=7; min_data_in_leaf=581; feature_fraction=0.819; bagging_fraction=0.768; learning_rate=0.0205 : y = 0.929 : 171.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 03:13:20 PM 2025 AUC 0.929504909700677\n",
            "\n",
            "[mbo] 7: num_leaves=1672; max_depth=15; min_data_in_leaf=554; feature_fraction=0.904; bagging_fraction=0.769; learning_rate=0.0141 : y = 0.93 : 271.8 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:15:54 PM 2025 AUC 0.929325310647476\n",
            "\n",
            "[mbo] 8: num_leaves=1807; max_depth=6; min_data_in_leaf=202; feature_fraction=0.739; bagging_fraction=0.445; learning_rate=0.0186 : y = 0.929 : 152.7 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:19:01 PM 2025 AUC 0.92998555887055\n",
            "\n",
            "[mbo] 9: num_leaves=1996; max_depth=8; min_data_in_leaf=475; feature_fraction=0.744; bagging_fraction=0.511; learning_rate=0.032 : y = 0.93 : 186.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 10 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 03:21:27 PM 2025 AUC 0.928863441611468\n",
            "\n",
            "[mbo] 10: num_leaves=1900; max_depth=5; min_data_in_leaf=516; feature_fraction=0.976; bagging_fraction=0.681; learning_rate=0.0133 : y = 0.929 : 146.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:25:07 PM 2025 AUC 0.928409596271928\n",
            "\n",
            "[mbo] 11: num_leaves=1870; max_depth=10; min_data_in_leaf=672; feature_fraction=0.873; bagging_fraction=0.869; learning_rate=0.0464 : y = 0.928 : 219.4 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:28:43 PM 2025 AUC 0.929709723136028\n",
            "\n",
            "[mbo] 12: num_leaves=1634; max_depth=10; min_data_in_leaf=540; feature_fraction=0.726; bagging_fraction=0.481; learning_rate=0.0179 : y = 0.93 : 215.2 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:33:18 PM 2025 AUC 0.930422794928056\n",
            "\n",
            "[mbo] 13: num_leaves=1950; max_depth=8; min_data_in_leaf=542; feature_fraction=0.411; bagging_fraction=0.55; learning_rate=0.0366 : y = 0.93 : 274.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 14 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 03:37:52 PM 2025 AUC 0.929939824490302\n",
            "\n",
            "[mbo] 14: num_leaves=1760; max_depth=6; min_data_in_leaf=634; feature_fraction=0.467; bagging_fraction=0.443; learning_rate=0.036 : y = 0.93 : 272.6 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:41:55 PM 2025 AUC 0.930383795844666\n",
            "\n",
            "[mbo] 15: num_leaves=1980; max_depth=9; min_data_in_leaf=795; feature_fraction=0.306; bagging_fraction=0.782; learning_rate=0.0344 : y = 0.93 : 242.5 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:46:16 PM 2025 AUC 0.930366663664127\n",
            "\n",
            "[mbo] 16: num_leaves=1819; max_depth=10; min_data_in_leaf=731; feature_fraction=0.34; bagging_fraction=0.846; learning_rate=0.0177 : y = 0.93 : 259.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 17 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 03:49:55 PM 2025 AUC 0.931579151816358\n",
            "\n",
            "[mbo] 17: num_leaves=2047; max_depth=8; min_data_in_leaf=623; feature_fraction=0.233; bagging_fraction=0.626; learning_rate=0.0338 : y = 0.932 : 219.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:53:35 PM 2025 AUC 0.929631451701567\n",
            "\n",
            "[mbo] 18: num_leaves=1931; max_depth=7; min_data_in_leaf=201; feature_fraction=0.207; bagging_fraction=0.617; learning_rate=0.0319 : y = 0.93 : 219.1 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 03:57:08 PM 2025 AUC 0.930818179848233\n",
            "\n",
            "[mbo] 19: num_leaves=1976; max_depth=7; min_data_in_leaf=632; feature_fraction=0.2; bagging_fraction=0.656; learning_rate=0.0231 : y = 0.931 : 212.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 20 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 04:00:45 PM 2025 AUC 0.929256789411282\n",
            "\n",
            "[mbo] 20: num_leaves=1975; max_depth=8; min_data_in_leaf=851; feature_fraction=0.207; bagging_fraction=0.6; learning_rate=0.0329 : y = 0.929 : 216.9 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:04:49 PM 2025 AUC 0.929901456949981\n",
            "\n",
            "[mbo] 21: num_leaves=2048; max_depth=4; min_data_in_leaf=209; feature_fraction=0.425; bagging_fraction=0.48; learning_rate=0.00816 : y = 0.93 : 243.1 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:08:42 PM 2025 AUC 0.929647398827417\n",
            "\n",
            "[mbo] 22: num_leaves=1549; max_depth=8; min_data_in_leaf=604; feature_fraction=0.262; bagging_fraction=0.758; learning_rate=0.0467 : y = 0.93 : 232.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 23 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 04:12:53 PM 2025 AUC 0.92998995107192\n",
            "\n",
            "[mbo] 23: num_leaves=2043; max_depth=10; min_data_in_leaf=622; feature_fraction=0.249; bagging_fraction=0.823; learning_rate=0.0322 : y = 0.93 : 249.3 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:17:02 PM 2025 AUC 0.929195634775531\n",
            "\n",
            "[mbo] 24: num_leaves=2044; max_depth=9; min_data_in_leaf=569; feature_fraction=0.27; bagging_fraction=0.631; learning_rate=0.0601 : y = 0.929 : 247.8 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:20:36 PM 2025 AUC 0.930440929284352\n",
            "\n",
            "[mbo] 25: num_leaves=1190; max_depth=9; min_data_in_leaf=657; feature_fraction=0.208; bagging_fraction=0.611; learning_rate=0.0357 : y = 0.93 : 213.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 04:24:05 PM 2025 AUC 0.927596605694483\n",
            "\n",
            "[mbo] 26: num_leaves=1527; max_depth=9; min_data_in_leaf=931; feature_fraction=0.946; bagging_fraction=0.877; learning_rate=0.00526 : y = 0.928 : 208.7 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:27:44 PM 2025 AUC 0.930459445806593\n",
            "\n",
            "[mbo] 27: num_leaves=2023; max_depth=4; min_data_in_leaf=614; feature_fraction=0.345; bagging_fraction=0.639; learning_rate=0.0357 : y = 0.93 : 218.5 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:31:51 PM 2025 AUC 0.929920990482218\n",
            "\n",
            "[mbo] 28: num_leaves=2047; max_depth=10; min_data_in_leaf=356; feature_fraction=0.218; bagging_fraction=0.523; learning_rate=0.0167 : y = 0.93 : 245.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 29 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 04:35:52 PM 2025 AUC 0.930989677589693\n",
            "\n",
            "[mbo] 29: num_leaves=1929; max_depth=9; min_data_in_leaf=561; feature_fraction=0.23; bagging_fraction=0.739; learning_rate=0.016 : y = 0.931 : 240.9 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:41:49 PM 2025 AUC 0.92990886787233\n",
            "\n",
            "[mbo] 30: num_leaves=1846; max_depth=10; min_data_in_leaf=477; feature_fraction=0.507; bagging_fraction=0.688; learning_rate=0.0051 : y = 0.93 : 355.7 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:45:22 PM 2025 AUC 0.930494262126407\n",
            "\n",
            "[mbo] 31: num_leaves=1955; max_depth=6; min_data_in_leaf=436; feature_fraction=0.22; bagging_fraction=0.319; learning_rate=0.0181 : y = 0.93 : 212.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 32 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 04:48:45 PM 2025 AUC 0.930201102923541\n",
            "\n",
            "[mbo] 32: num_leaves=2046; max_depth=6; min_data_in_leaf=210; feature_fraction=0.207; bagging_fraction=0.947; learning_rate=0.0208 : y = 0.93 : 202.2 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:52:31 PM 2025 AUC 0.929300821758319\n",
            "\n",
            "[mbo] 33: num_leaves=1984; max_depth=8; min_data_in_leaf=512; feature_fraction=0.215; bagging_fraction=0.579; learning_rate=0.0342 : y = 0.929 : 224.7 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 04:55:56 PM 2025 AUC 0.928791550395549\n",
            "\n",
            "[mbo] 34: num_leaves=2046; max_depth=5; min_data_in_leaf=1036; feature_fraction=0.235; bagging_fraction=0.581; learning_rate=0.0248 : y = 0.929 : 204.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 35 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 05:00:22 PM 2025 AUC 0.930466594554905\n",
            "\n",
            "[mbo] 35: num_leaves=1562; max_depth=11; min_data_in_leaf=631; feature_fraction=0.28; bagging_fraction=0.615; learning_rate=0.0209 : y = 0.93 : 265.1 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:05:23 PM 2025 AUC 0.930691227408631\n",
            "\n",
            "[mbo] 36: num_leaves=2037; max_depth=9; min_data_in_leaf=621; feature_fraction=0.485; bagging_fraction=0.596; learning_rate=0.0328 : y = 0.931 : 300.1 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:08:39 PM 2025 AUC 0.929347665163142\n",
            "\n",
            "[mbo] 37: num_leaves=1446; max_depth=9; min_data_in_leaf=726; feature_fraction=0.663; bagging_fraction=0.635; learning_rate=0.0327 : y = 0.929 : 195.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 38 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 05:13:35 PM 2025 AUC 0.929654305384905\n",
            "\n",
            "[mbo] 38: num_leaves=1679; max_depth=9; min_data_in_leaf=580; feature_fraction=0.451; bagging_fraction=0.715; learning_rate=0.0264 : y = 0.93 : 294.8 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:17:28 PM 2025 AUC 0.930102955691337\n",
            "\n",
            "[mbo] 39: num_leaves=2034; max_depth=9; min_data_in_leaf=659; feature_fraction=0.25; bagging_fraction=0.545; learning_rate=0.0382 : y = 0.93 : 232.6 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:22:11 PM 2025 AUC 0.931006824377648\n",
            "\n",
            "[mbo] 40: num_leaves=2048; max_depth=9; min_data_in_leaf=663; feature_fraction=0.378; bagging_fraction=0.663; learning_rate=0.031 : y = 0.931 : 282.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 41 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 05:27:02 PM 2025 AUC 0.929723244946648\n",
            "\n",
            "[mbo] 41: num_leaves=790; max_depth=9; min_data_in_leaf=595; feature_fraction=0.435; bagging_fraction=0.539; learning_rate=0.028 : y = 0.93 : 289.4 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:30:47 PM 2025 AUC 0.92999120027481\n",
            "\n",
            "[mbo] 42: num_leaves=1188; max_depth=9; min_data_in_leaf=609; feature_fraction=0.23; bagging_fraction=0.683; learning_rate=0.00905 : y = 0.93 : 224.2 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:35:53 PM 2025 AUC 0.929843911333219\n",
            "\n",
            "[mbo] 43: num_leaves=2048; max_depth=11; min_data_in_leaf=620; feature_fraction=0.452; bagging_fraction=0.629; learning_rate=0.0253 : y = 0.93 : 305.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 44 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 05:40:24 PM 2025 AUC 0.928717019119693\n",
            "\n",
            "[mbo] 44: num_leaves=2048; max_depth=7; min_data_in_leaf=436; feature_fraction=0.424; bagging_fraction=0.382; learning_rate=0.0339 : y = 0.929 : 270.6 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:45:02 PM 2025 AUC 0.929529871595376\n",
            "\n",
            "[mbo] 45: num_leaves=1812; max_depth=9; min_data_in_leaf=588; feature_fraction=0.398; bagging_fraction=0.648; learning_rate=0.0393 : y = 0.93 : 276.9 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:49:08 PM 2025 AUC 0.930365141906233\n",
            "\n",
            "[mbo] 46: num_leaves=1176; max_depth=8; min_data_in_leaf=461; feature_fraction=0.315; bagging_fraction=0.66; learning_rate=0.0159 : y = 0.93 : 245.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 47 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 05:54:02 PM 2025 AUC 0.929153007411797\n",
            "\n",
            "[mbo] 47: num_leaves=1032; max_depth=10; min_data_in_leaf=220; feature_fraction=0.383; bagging_fraction=0.588; learning_rate=0.0205 : y = 0.929 : 293.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 05:58:34 PM 2025 AUC 0.929187386244245\n",
            "\n",
            "[mbo] 48: num_leaves=1173; max_depth=13; min_data_in_leaf=254; feature_fraction=0.257; bagging_fraction=0.665; learning_rate=0.0354 : y = 0.929 : 271.0 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:01:57 PM 2025 AUC 0.930206331726864\n",
            "\n",
            "[mbo] 49: num_leaves=1892; max_depth=4; min_data_in_leaf=283; feature_fraction=0.283; bagging_fraction=0.554; learning_rate=0.0179 : y = 0.93 : 202.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 50 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 06:05:59 PM 2025 AUC 0.930076365289287\n",
            "\n",
            "[mbo] 50: num_leaves=1596; max_depth=7; min_data_in_leaf=277; feature_fraction=0.324; bagging_fraction=0.719; learning_rate=0.0182 : y = 0.93 : 240.7 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:10:46 PM 2025 AUC 0.92973311755825\n",
            "\n",
            "[mbo] 51: num_leaves=2048; max_depth=7; min_data_in_leaf=208; feature_fraction=0.47; bagging_fraction=0.74; learning_rate=0.0149 : y = 0.93 : 286.6 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:15:30 PM 2025 AUC 0.930784413439964\n",
            "\n",
            "[mbo] 52: num_leaves=1152; max_depth=12; min_data_in_leaf=528; feature_fraction=0.329; bagging_fraction=0.821; learning_rate=0.0172 : y = 0.931 : 282.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 06:18:38 PM 2025 AUC 0.929656998552383\n",
            "\n",
            "[mbo] 53: num_leaves=2047; max_depth=8; min_data_in_leaf=660; feature_fraction=0.772; bagging_fraction=0.652; learning_rate=0.0382 : y = 0.93 : 187.3 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:22:33 PM 2025 AUC 0.930793751499103\n",
            "\n",
            "[mbo] 54: num_leaves=2048; max_depth=8; min_data_in_leaf=899; feature_fraction=0.272; bagging_fraction=0.791; learning_rate=0.0155 : y = 0.931 : 234.4 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:26:34 PM 2025 AUC 0.930270439261705\n",
            "\n",
            "[mbo] 55: num_leaves=1944; max_depth=8; min_data_in_leaf=615; feature_fraction=0.298; bagging_fraction=0.459; learning_rate=0.0162 : y = 0.93 : 239.7 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 56 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 06:30:38 PM 2025 AUC 0.930383745023301\n",
            "\n",
            "[mbo] 56: num_leaves=1149; max_depth=8; min_data_in_leaf=713; feature_fraction=0.313; bagging_fraction=0.771; learning_rate=0.0215 : y = 0.93 : 243.1 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:34:23 PM 2025 AUC 0.929896043623097\n",
            "\n",
            "[mbo] 57: num_leaves=1863; max_depth=5; min_data_in_leaf=218; feature_fraction=0.339; bagging_fraction=0.333; learning_rate=0.00912 : y = 0.93 : 223.9 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:38:56 PM 2025 AUC 0.929493317548094\n",
            "\n",
            "[mbo] 58: num_leaves=1372; max_depth=8; min_data_in_leaf=625; feature_fraction=0.415; bagging_fraction=0.523; learning_rate=0.0357 : y = 0.929 : 272.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 59 in the file bayesiana.RDATA.\n",
            "\n",
            "Wed Sep 03 06:43:18 PM 2025 AUC 0.930905365410404\n",
            "\n",
            "[mbo] 59: num_leaves=1235; max_depth=9; min_data_in_leaf=393; feature_fraction=0.331; bagging_fraction=0.93; learning_rate=0.0119 : y = 0.931 : 261.2 secs : infill_ei\n",
            "\n",
            "Wed Sep 03 06:47:39 PM 2025 AUC 0.929426715533196\n",
            "\n",
            "[mbo] 60: num_leaves=1054; max_depth=11; min_data_in_leaf=204; feature_fraction=0.234; bagging_fraction=0.892; learning_rate=0.0154 : y = 0.929 : 259.8 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ssk5nnMk6INK",
        "outputId": "1a994754-2e63-4736-9d29-e3223bd9d8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'num_leaves'</li><li>'max_depth'</li><li>'min_data_in_leaf'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'learning_rate'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/markdown": "1. 'num_leaves'\n2. 'max_depth'\n3. 'min_data_in_leaf'\n4. 'feature_fraction'\n5. 'bagging_fraction'\n6. 'learning_rate'\n7. 'y'\n8. 'dob'\n9. 'eol'\n10. 'error.message'\n11. 'exec.time'\n12. 'ei'\n13. 'error.model'\n14. 'train.time'\n15. 'prop.type'\n16. 'propose.time'\n17. 'se'\n18. 'mean'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'num\\_leaves'\n\\item 'max\\_depth'\n\\item 'min\\_data\\_in\\_leaf'\n\\item 'feature\\_fraction'\n\\item 'bagging\\_fraction'\n\\item 'learning\\_rate'\n\\item 'y'\n\\item 'dob'\n\\item 'eol'\n\\item 'error.message'\n\\item 'exec.time'\n\\item 'ei'\n\\item 'error.model'\n\\item 'train.time'\n\\item 'prop.type'\n\\item 'propose.time'\n\\item 'se'\n\\item 'mean'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"num_leaves\"       \"max_depth\"        \"min_data_in_leaf\" \"feature_fraction\"\n",
              " [5] \"bagging_fraction\" \"learning_rate\"    \"y\"                \"dob\"             \n",
              " [9] \"eol\"              \"error.message\"    \"exec.time\"        \"ei\"              \n",
              "[13] \"error.model\"      \"train.time\"       \"prop.type\"        \"propose.time\"    \n",
              "[17] \"se\"               \"mean\"            "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u4zq-vknhjGc"
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E8v2eA427N8e"
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iBTWexVU7PGC",
        "outputId": "73db83a0-641e-4ca0-bc13-b17f8172d450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   num_leaves max_depth min_data_in_leaf feature_fraction bagging_fraction\n",
            "        <int>     <int>            <int>            <num>            <num>\n",
            "1:       2047         8              623        0.2334134        0.6256265\n",
            "   learning_rate\n",
            "           <num>\n",
            "1:    0.03384619\n",
            "[1] 0.9315792\n"
          ]
        }
      ],
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsVZmAnhwX-"
      },
      "source": [
        "## 2.3  Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      },
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "eDqfyA14hzwv"
      },
      "outputs": [],
      "source": [
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings= FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qFmFivf5Iet"
      },
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lg5WVZncvc7H"
      },
      "outputs": [],
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yc9QzXREv0xf"
      },
      "outputs": [],
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "thjdqEBLuvNt"
      },
      "outputs": [],
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      },
      "source": [
        "#### Final Training Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FgCcvBfEwImu",
        "outputId": "e65b0204-994d-4089-8f7e-9d9f82f709b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>600019</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>8</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.001</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.625626548583892</dd>\n",
              "\t<dt>$pos_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$neg_bagging_fraction</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$drop_rate</dt>\n",
              "\t\t<dd>0.1</dd>\n",
              "\t<dt>$max_drop</dt>\n",
              "\t\t<dd>50</dd>\n",
              "\t<dt>$skip_drop</dt>\n",
              "\t\t<dd>0.5</dd>\n",
              "\t<dt>$extra_trees</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>1200</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0338461855358719</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.233413387342142</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>2047</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>623</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$boosting\n:   'gbdt'\n$objective\n:   'binary'\n$metric\n:   'auc'\n$first_metric_only\n:   FALSE\n$boost_from_average\n:   TRUE\n$feature_pre_filter\n:   FALSE\n$force_row_wise\n:   TRUE\n$verbosity\n:   -100\n$seed\n:   600019\n$max_depth\n:   8\n$min_gain_to_split\n:   0\n$min_sum_hessian_in_leaf\n:   0.001\n$lambda_l1\n:   0\n$lambda_l2\n:   0\n$max_bin\n:   31\n$bagging_fraction\n:   0.625626548583892\n$pos_bagging_fraction\n:   1\n$neg_bagging_fraction\n:   1\n$is_unbalance\n:   FALSE\n$scale_pos_weight\n:   1\n$drop_rate\n:   0.1\n$max_drop\n:   50\n$skip_drop\n:   0.5\n$extra_trees\n:   FALSE\n$num_iterations\n:   1200\n$learning_rate\n:   0.0338461855358719\n$feature_fraction\n:   0.233413387342142\n$num_leaves\n:   2047\n$min_data_in_leaf\n:   623\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$boosting] 'gbdt'\n\\item[\\$objective] 'binary'\n\\item[\\$metric] 'auc'\n\\item[\\$first\\_metric\\_only] FALSE\n\\item[\\$boost\\_from\\_average] TRUE\n\\item[\\$feature\\_pre\\_filter] FALSE\n\\item[\\$force\\_row\\_wise] TRUE\n\\item[\\$verbosity] -100\n\\item[\\$seed] 600019\n\\item[\\$max\\_depth] 8\n\\item[\\$min\\_gain\\_to\\_split] 0\n\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n\\item[\\$lambda\\_l1] 0\n\\item[\\$lambda\\_l2] 0\n\\item[\\$max\\_bin] 31\n\\item[\\$bagging\\_fraction] 0.625626548583892\n\\item[\\$pos\\_bagging\\_fraction] 1\n\\item[\\$neg\\_bagging\\_fraction] 1\n\\item[\\$is\\_unbalance] FALSE\n\\item[\\$scale\\_pos\\_weight] 1\n\\item[\\$drop\\_rate] 0.1\n\\item[\\$max\\_drop] 50\n\\item[\\$skip\\_drop] 0.5\n\\item[\\$extra\\_trees] FALSE\n\\item[\\$num\\_iterations] 1200\n\\item[\\$learning\\_rate] 0.0338461855358719\n\\item[\\$feature\\_fraction] 0.233413387342142\n\\item[\\$num\\_leaves] 2047\n\\item[\\$min\\_data\\_in\\_leaf] 623\n\\end{description}\n",
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] FALSE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 600019\n",
              "\n",
              "$max_depth\n",
              "[1] 8\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 0\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.001\n",
              "\n",
              "$lambda_l1\n",
              "[1] 0\n",
              "\n",
              "$lambda_l2\n",
              "[1] 0\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.6256265\n",
              "\n",
              "$pos_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$neg_bagging_fraction\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] FALSE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$drop_rate\n",
              "[1] 0.1\n",
              "\n",
              "$max_drop\n",
              "[1] 50\n",
              "\n",
              "$skip_drop\n",
              "[1] 0.5\n",
              "\n",
              "$extra_trees\n",
              "[1] FALSE\n",
              "\n",
              "$num_iterations\n",
              "[1] 1200\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.03384619\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.2334134\n",
              "\n",
              "$num_leaves\n",
              "[1] 2047\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 623\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZIYn4l95TBH"
      },
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vPLsd4mMRe4u"
      },
      "outputs": [],
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "WRI_-taRwOXO"
      },
      "outputs": [],
      "source": [
        "  # entreno LightGBM\n",
        "\n",
        "  modelo_final <- lgb.train(\n",
        "    data= dtrain,\n",
        "    param= param_normalizado\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_bkhnCvj0g3Q"
      },
      "outputs": [],
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lZ3sLmbh0kFj"
      },
      "outputs": [],
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEtp2--t5Ymg"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI5008Mj5ZdI"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "PimBY3N_0ryP"
      },
      "outputs": [],
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D26rNRh55gpw"
      },
      "source": [
        "#### Tabla Prediccion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "RJwg7LHd11yu"
      },
      "outputs": [],
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOt4eG_55ltv"
      },
      "source": [
        "Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gWW3tatE12je",
        "outputId": "922ce0f7-952f-4a36-a42c-1a28f57dc46c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
            "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
            "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
            "Successfully submitted to Data Mining, Analista Sr 2025 B \n",
            "Successfully submitted to Data Mining, Analista Sr 2025 B \n"
          ]
        }
      ],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "B9tB2X4439Hg"
      },
      "outputs": [],
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9zA_W25c15DP",
        "outputId": "03fc1000-7ad8-4ced-b655-35f9e516ec93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Wed Sep 03 06:50:41 PM 2025'"
            ],
            "text/markdown": "'Wed Sep 03 06:50:41 PM 2025'",
            "text/latex": "'Wed Sep 03 06:50:41 PM 2025'",
            "text/plain": [
              "[1] \"Wed Sep 03 06:50:41 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVZucdLHzZ0"
      },
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar04**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}