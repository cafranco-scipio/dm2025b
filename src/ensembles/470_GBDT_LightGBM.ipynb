{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O94qX1svwzoC"
   },
   "source": [
    "# 4. Ensembles de Arboles de Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsJFTcBZw1bE"
   },
   "source": [
    "## 4.06 GBDT LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsgvDbemw9Tc"
   },
   "source": [
    "La técnica de Gradient Boosting fue creada por Jerome H. Friedman en 1999 - 2001\n",
    "<br>Se implementaron librerías ineficientes\n",
    "<br>En 2016 se crea XGBoost, en 2017 LightGBM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o-6jjy0Yedk"
   },
   "source": [
    "Paper original de  Gradient Boosting\n",
    "\n",
    "\n",
    "Friedman JH. Greedy function approximation: A gradient\n",
    "boosting machine. Ann Stat. 2001;29(5):1189–232. https://\n",
    "doi.org/10.1214/aos/1013203451.\n",
    "<br>\n",
    "https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14MlfCxMZWIc"
   },
   "source": [
    "Paper XGBoost\n",
    "\n",
    "Chen, T.; Guestrin, C. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd ACM Sigkdd International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, 13–17 August 2016; pp. 785–794.\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/2939672.2939785"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDk5edloZpBI"
   },
   "source": [
    "Paper  LightGBM\n",
    "\n",
    "Ke G., Meng Q., Finley T., Wang T., Chen W., Ma W., et al.\n",
    "Lightgbm: A highly efficient gradient boosting decision tree\n",
    "Advances in Neural Information Processing Systems, 30 (2017)\n",
    "\n",
    "https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMyXpQyJaCsP"
   },
   "source": [
    "Videos \"simplificados\" :\n",
    "*  https://www.youtube.com/watch?v=3CC4N4z3GJc\n",
    "*  https://www.youtube.com/watch?v=2xudPOBz-vs\n",
    "*  https://www.youtube.com/watch?v=jxuNLH5dXCs\n",
    "*  https://www.youtube.com/watch?v=StWY5QWMXCw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eyffb3AAahth"
   },
   "source": [
    "Artículos ligeros:\n",
    "*  https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
    "*   https://www.machinelearningplus.com/machine-learning/an-introduction-to-gradient-boosting-decision-trees/\n",
    "*   https://medium.com/@ruchi.awasthi63/gradient-boosted-decision-tree-clearly-explained-bd1d8c7d9923\n",
    "*   https://medium.com/data-science/a-visual-understanding-of-decision-trees-and-gradient-boosting-c6bc53f982ce\n",
    "*   https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b\n",
    "*   https://medium.com/@datasciencewizards/understanding-the-gradient-boosting-algorithm-9fe698a352ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YOyfUaESdsX"
   },
   "source": [
    "El Gradient Boosting of Decision Trees es un ensemble de árboles de decisión, para un nuevo registro la predicción se hace sumando el score que cada arbol asigna a ese registro.\n",
    "\n",
    "En GBDT la construccion de los árboles es secuencial, ya que el arbol n-simo se genera para predecir el error del modelo conformado por los n-1 arboles previos, aunque sea un arbol de clasificación lo que se predice es un numero real mediante un arbol de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF6XblBIYnY6"
   },
   "source": [
    "<br>Qué tipo de perturbaciones se realiza LightGBM\n",
    "\n",
    "*   Se perturba el dataset, seleccionando para cada arbol un subconjunto de las columnas.\n",
    "*   El algortimo de arbol de decisión no presenta perturbaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j75A--Tsx2df"
   },
   "source": [
    "Cada arbolito de LightGBM se entrena sobre un dataset perturbado, que en principio posee :\n",
    "* todos los registros del dataset original\n",
    "* solo un porcentaje *feature_fraction* de las columnas originales del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 4.06.1  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "### 4.07  LightGBM, una corrida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSU5vi00CPRS"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq8dySimCPRT"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tjda_YGOXaPw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Fri Aug 29 23:37:57 2025'"
      ],
      "text/latex": [
       "'Fri Aug 29 23:37:57 2025'"
      ],
      "text/markdown": [
       "'Fri Aug 29 23:37:57 2025'"
      ],
      "text/plain": [
       "[1] \"Fri Aug 29 23:37:57 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1iE0U4_WCPRT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 656930</td><td>35.1</td><td>1439368</td><td>76.9</td><td>1431365</td><td>76.5</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1224871</td><td> 9.4</td><td>8388608</td><td>64.0</td><td>1924959</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  656930 & 35.1 & 1439368 & 76.9 & 1431365 & 76.5\\\\\n",
       "\tVcells & 1224871 &  9.4 & 8388608 & 64.0 & 1924959 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  656930 | 35.1 | 1439368 | 76.9 | 1431365 | 76.5 |\n",
       "| Vcells | 1224871 |  9.4 | 8388608 | 64.0 | 1924959 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  656930 35.1 1439368    76.9 1431365  76.5\n",
       "Vcells 1224871  9.4 8388608    64.0 1924959  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BJDwdD0dCPRU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: rpart\n",
      "\n",
      "Loading required package: rlist\n",
      "\n",
      "Loading required package: lightgbm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"rpart\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8-Pyp6CCPRU"
   },
   "source": [
    "Aqui debe cargar SU semilla primigenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "peRH7ySLCPRV"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4070\n",
    "PARAM$semilla_primigenia <- 102191\n",
    "\n",
    "# estos hiperparametros de LightGBM surgieron de una Bayesian Optimization\n",
    "PARAM$lgb$num_iterations <- 1000  # cantidad de arbolitos\n",
    "PARAM$lgb$learning_rate <- 0.027\n",
    "PARAM$lgb$feature_fraction <- 0.8\n",
    "PARAM$lgb$min_data_in_leaf <- 76\n",
    "PARAM$lgb$num_leaves <- 8\n",
    "PARAM$lgb$max_bin <- 31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1gZD6ZMvCPRV"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"KA\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xi0emX2ECPRV"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\", stringsAsFactors= TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-3XuBeDy1Ugj"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria\n",
    "\n",
    "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\"), 1L, 0L)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h8Anoo4Sel8S"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(colnames(dataset), c(\"clase_ternaria\", \"clase01\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RA3cSJ6KaGwA"
   },
   "outputs": [],
   "source": [
    "# establezco donde entreno\n",
    "\n",
    "dataset[, train := 0L]\n",
    "dataset[foto_mes %in% c(202107), train := 1L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T6Zr06HB1kMU"
   },
   "outputs": [],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[train == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset[train == 1L, clase01]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TI9_5pii2zCF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1248, number of negative: 163348\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.205627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3612\n",
      "[LightGBM] [Info] Number of data points in the train set: 164596, number of used features: 153\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.007582 -> initscore=-4.874341\n",
      "[LightGBM] [Info] Start training from score -4.874341\n"
     ]
    }
   ],
   "source": [
    "# genero el modelo\n",
    "# estos hiperparametros  salieron de una laaarga Optmizacion Bayesiana\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\") # Establezco la semilla aleatoria\n",
    "\n",
    "modelo <- lgb.train(\n",
    "  data= dtrain,\n",
    "  param= list(\n",
    "    objective= \"binary\",\n",
    "    max_bin= PARAM$lgb$max_bin,\n",
    "    learning_rate= PARAM$lgb$learning_rate,\n",
    "    num_iterations= PARAM$lgb$num_iterations,\n",
    "    num_leaves= PARAM$lgb$num_leaves,\n",
    "    min_data_in_leaf= PARAM$lgb$min_data_in_leaf,\n",
    "    feature_fraction= PARAM$lgb$feature_fraction,\n",
    "    seed= PARAM$semilla_primigenia\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "69QcMsSkg9d-"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "tb_importancia <- as.data.table(lgb.importance(modelo))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite(tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lauiNeQDg-XP"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(modelo, \"modelo.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VQhEcNmBhF7u"
   },
   "outputs": [],
   "source": [
    "# aplico el modelo a los datos sin clase\n",
    "dfuture <- dataset[foto_mes == 202109]\n",
    "\n",
    "# aplico el modelo a los datos nuevos\n",
    "prediccion <- predict(\n",
    "  modelo,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Z5LYpStThlIC"
   },
   "outputs": [],
   "source": [
    "# tabla de prediccion\n",
    "\n",
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion ]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vSopCODCh6kL"
   },
   "outputs": [],
   "source": [
    "# subidas a Kaggle\n",
    "# ordeno por probabilidad descendente\n",
    "\n",
    "setorder(tb_prediccion, -prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pmxc2Z0fpJAZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in system(linea, intern = TRUE):\n",
      "“running command 'kaggle competitions submit -c data-mining-analista-sr-2025-b -f KA4070.csv -m 'num_iterations=1000  learning_rate=0.027  feature_fraction=0.8  min_data_in_leaf=76  num_leaves=8  max_bin=31'' had status 1”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 Client Error: Unauthorized for url: https://www.kaggle.com/api/v1/competitions/submission-url"
     ]
    }
   ],
   "source": [
    "# genero la prediccion y subo a Kaggle\n",
    "\n",
    "tb_prediccion[, Predicted := 0L]\n",
    "tb_prediccion[prob>(1/40), Predicted := 1L]\n",
    "\n",
    "archivo_kaggle <- paste0(\"KA\", PARAM$experimento, \".csv\")\n",
    "\n",
    "# grabo el archivo\n",
    "fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "  file= archivo_kaggle,\n",
    "  sep= \",\"\n",
    ")\n",
    "\n",
    "# subida a Kaggle\n",
    "comando <- \"kaggle competitions submit\"\n",
    "competencia <- \"-c data-mining-analista-sr-2025-b\"\n",
    "arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "mensaje <- paste0(\"-m 'num_iterations=\", PARAM$lgb$num_iterations,\n",
    "  \"  learning_rate=\", PARAM$lgb$learning_rate,\n",
    "  \"  feature_fraction=\", PARAM$lgb$feature_fraction,\n",
    "  \"  min_data_in_leaf=\", PARAM$lgb$min_data_in_leaf,\n",
    "  \"  num_leaves=\",PARAM$lgb$num_leaves,\n",
    "  \"  max_bin=\", PARAM$lgb$max_bin,\n",
    "\"'\" )\n",
    "\n",
    "linea <- paste( comando, competencia, arch, mensaje)\n",
    "salida <- system(linea, intern=TRUE)\n",
    "cat(salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "PK3QGWJsXk_k"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/latex": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/markdown": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/plain": [
       "[1] \"Fri Aug 29 23:40:00 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMr6Z1enOyd3"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lO4QwOEU-xPe"
   },
   "source": [
    "### 4.08  LightGBM  optimizacion de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75FU3LjSF2uN"
   },
   "source": [
    "La optimizacion de los hiperparámetros de LightGBM mediante el método de optimizacion bayesiana será su *caballito de batalla* durante la asignatura !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJBO5Dcb_B7s"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2CeMTfCuX3bH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/latex": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/markdown": [
       "'Fri Aug 29 23:40:00 2025'"
      ],
      "text/plain": [
       "[1] \"Fri Aug 29 23:40:00 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HPKFI6yP_B7s"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>1821904</td><td>97.4</td><td>  3711614</td><td>198.3</td><td>  3711614</td><td> 198.3</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>3461499</td><td>26.5</td><td>115653749</td><td>882.4</td><td>133628647</td><td>1019.6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells & 1821904 & 97.4 &   3711614 & 198.3 &   3711614 &  198.3\\\\\n",
       "\tVcells & 3461499 & 26.5 & 115653749 & 882.4 & 133628647 & 1019.6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells | 1821904 | 97.4 |   3711614 | 198.3 |   3711614 |  198.3 |\n",
       "| Vcells | 3461499 | 26.5 | 115653749 | 882.4 | 133628647 | 1019.6 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb)  max used  (Mb)  \n",
       "Ncells 1821904 97.4   3711614  198.3   3711614  198.3\n",
       "Vcells 3461499 26.5 115653749  882.4 133628647 1019.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B6X8U6XF_B7t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: primes\n",
      "\n",
      "Loading required package: DiceKriging\n",
      "\n",
      "Loading required package: mlrMBO\n",
      "\n",
      "Loading required package: mlr\n",
      "\n",
      "Loading required package: ParamHelpers\n",
      "\n",
      "Loading required package: smoof\n",
      "\n",
      "Loading required package: checkmate\n",
      "\n",
      "\n",
      "Attaching package: ‘checkmate’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:DiceKriging’:\n",
      "\n",
      "    checkNames\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"rpart\")\n",
    "require(\"parallel\")\n",
    "\n",
    "if( !require(\"primes\") ) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "\n",
    "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
    "require(\"rlist\")\n",
    "\n",
    "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qZHeAHdCJQ2"
   },
   "source": [
    "Aqui debe cargar SU semilla primigenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2y3Ai8F6CJQ2"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$experimento <- 4080\n",
    "PARAM$semilla_primigenia <- 102191\n",
    "\n",
    "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
    "# undersampling de 1.0  implica tomar TODOS los datos\n",
    "PARAM$trainingstrategy$undersampling <- 1.0\n",
    "\n",
    "PARAM$hyperparametertuning$iteraciones <- 30 # iteracines bayesianas\n",
    "\n",
    "PARAM$hyperparametertuning$xval_folds <- 5\n",
    "\n",
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  max_bin= 31,\n",
    "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
    "  early_stopping_rounds= 200\n",
    ")\n",
    "\n",
    "# Aqui se cargan los bordes de los hiperparametros\n",
    "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
    "  makeNumericParam(\"learning_rate\", lower= 0.01, upper= 0.3),\n",
    "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 1.0),\n",
    "  makeIntegerParam(\"num_leaves\", lower= 8L, upper= 2048L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower= 1L, upper= 8000L)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NnPKiCHuCwVo"
   },
   "outputs": [],
   "source": [
    "# En el argumento x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC de cross validation del modelo entrenado\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"))\n",
    "\n",
    "  # uno la lista de hiperparametros : fijos + variables\n",
    "  param_completo <- c(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelocv <- lgb.cv(\n",
    "    data= dtrain,\n",
    "    nfold= PARAM$hyperparametertuning$xval_folds,\n",
    "    stratified= TRUE,\n",
    "    param= param_completo,\n",
    "    verbose= -100\n",
    "  )\n",
    "\n",
    "  # obtengo la ganancia\n",
    "  AUC <- modelocv$best_score\n",
    "\n",
    "  # esta es la forma de devolver un parametro extra\n",
    "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelocv$best_iter)\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelocv)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  message( \"AUC: \", AUC)\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7Pw1KLeE3UH"
   },
   "source": [
    "aqui se inicia el programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "w1lb19whCJQ3"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QvOokHUvuolF"
   },
   "outputs": [],
   "source": [
    "# en este archivo quedan la evolucion binaria de la BO\n",
    "\n",
    "kbayesiana <- \"bayesiana.RDATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xcOJpoFvCJQ3"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JorOk_A8EhSy"
   },
   "outputs": [],
   "source": [
    "dataset <- dataset[foto_mes %in% c(202107)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JDg9xZVYrwvj"
   },
   "outputs": [],
   "source": [
    "# paso la clase a binaria que tome valores {0,1}  enteros\n",
    "\n",
    "dataset[\n",
    "  foto_mes %in% c(202107),\n",
    "  clase01 := ifelse(clase_ternaria == \"BAJA+2\", 1L, 0L)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "E68xpDYAr0nK"
   },
   "outputs": [],
   "source": [
    "# los campos que se van a utilizar\n",
    "\n",
    "campos_buenos <- setdiff(\n",
    "  colnames(dataset),\n",
    "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "G8zeYUfSr3GF"
   },
   "outputs": [],
   "source": [
    "# defino los datos que forma parte del training\n",
    "# aqui se hace el undersampling de los CONTINUA\n",
    "# notar que para esto utilizo la SEGUNDA semilla\n",
    "\n",
    "set.seed(PARAM$semilla_primigenia, kind= \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar := runif(nrow(dataset))]\n",
    "dataset[, training := 0L]\n",
    "\n",
    "dataset[\n",
    "  foto_mes %in% c(202107) &\n",
    "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
    "  training := 1L\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "se8_aKuMr5CV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "164596"
      ],
      "text/latex": [
       "164596"
      ],
      "text/markdown": [
       "164596"
      ],
      "text/plain": [
       "[1] 164596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "154"
      ],
      "text/latex": [
       "154"
      ],
      "text/markdown": [
       "154"
      ],
      "text/plain": [
       "[1] 154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dejo los datos en el formato que necesita LightGBM\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[training == 1L, campos_buenos, with= FALSE]),\n",
    "  label= dataset[training == 1L, clase01],\n",
    "  free_raw_data= FALSE\n",
    ")\n",
    "\n",
    "nrow(dtrain)\n",
    "ncol(dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CsRYGGeN-1ID"
   },
   "outputs": [],
   "source": [
    "# Aqui comienza la configuracion de la Bayesian Optimization\n",
    "\n",
    "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
    "\n",
    "configureMlr(show.learner.output= FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
    "  minimize= FALSE, # estoy Maximizando la ganancia\n",
    "  noisy= TRUE,\n",
    "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
    "  has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
    "  save.file.path= kbayesiana\n",
    ") # se graba cada 600 segundos\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "  ctrl,\n",
    "  iters= PARAM$hyperparametertuning$iteraciones\n",
    ") # cantidad de iteraciones\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales,\n",
    "# los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
    "\n",
    "# establezco la funcion que busca el maximo\n",
    "surr.km <- makeLearner(\n",
    "  \"regr.km\",\n",
    "  predict.type= \"se\",\n",
    "  covtype= \"matern3_2\",\n",
    "  control= list(trace= TRUE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "TissqCCHD1uZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing y column(s) for design. Not provided.\n",
      "\n",
      "Fri Aug 29 23:40:07 2025\n",
      "\n",
      "AUC: 0.90218829740043\n",
      "\n",
      "Fri Aug 29 23:52:51 2025\n",
      "\n",
      "AUC: 0.899027445720878\n",
      "\n",
      "Sat Aug 30 00:18:41 2025\n",
      "\n",
      "AUC: 0.901860250246459\n",
      "\n",
      "Sat Aug 30 00:23:49 2025\n",
      "\n",
      "AUC: 0.901285109376455\n",
      "\n",
      "Sat Aug 30 00:24:05 2025\n",
      "\n",
      "AUC: 0.903568581299174\n",
      "\n",
      "Sat Aug 30 00:24:30 2025\n",
      "\n",
      "AUC: 0.896799376665874\n",
      "\n",
      "Sat Aug 30 00:24:51 2025\n",
      "\n",
      "AUC: 0.903442262028602\n",
      "\n",
      "Sat Aug 30 00:25:16 2025\n",
      "\n",
      "AUC: 0.901658589496681\n",
      "\n",
      "Sat Aug 30 00:25:36 2025\n",
      "\n",
      "AUC: 0.887634671651531\n",
      "\n",
      "Sat Aug 30 00:26:08 2025\n",
      "\n",
      "AUC: 0.905409342597034\n",
      "\n",
      "Sat Aug 30 00:26:29 2025\n",
      "\n",
      "AUC: 0.88739170168463\n",
      "\n",
      "Sat Aug 30 00:27:09 2025\n",
      "\n",
      "AUC: 0.905687983422684\n",
      "\n",
      "Sat Aug 30 00:28:21 2025\n",
      "\n",
      "AUC: 0.903744360198627\n",
      "\n",
      "Sat Aug 30 00:28:45 2025\n",
      "\n",
      "AUC: 0.901780532142352\n",
      "\n",
      "Sat Aug 30 00:28:57 2025\n",
      "\n",
      "AUC: 0.905382068719131\n",
      "\n",
      "Sat Aug 30 00:29:15 2025\n",
      "\n",
      "AUC: 0.901073492533395\n",
      "\n",
      "[mbo] 0: learning_rate=0.163; feature_fraction=0.885; num_leaves=1385; min_data_in_leaf=4025 : y = 0.902 : 764.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.219; feature_fraction=0.545; num_leaves=1218; min_data_in_leaf=2664 : y = 0.899 : 1550.1 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.195; feature_fraction=0.376; num_leaves=1739; min_data_in_leaf=5302 : y = 0.902 : 307.7 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.131; feature_fraction=0.824; num_leaves=1953; min_data_in_leaf=3988 : y = 0.901 : 15.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.0736; feature_fraction=0.197; num_leaves=929; min_data_in_leaf=4663 : y = 0.904 : 24.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.174; feature_fraction=0.113; num_leaves=425; min_data_in_leaf=1980 : y = 0.897 : 21.2 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.104; feature_fraction=0.563; num_leaves=534; min_data_in_leaf=7985 : y = 0.903 : 25.0 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.0833; feature_fraction=0.696; num_leaves=1063; min_data_in_leaf=2301 : y = 0.902 : 20.3 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.286; feature_fraction=0.219; num_leaves=122; min_data_in_leaf=750 : y = 0.888 : 31.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.0382; feature_fraction=0.752; num_leaves=1874; min_data_in_leaf=6511 : y = 0.905 : 21.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.232; feature_fraction=0.639; num_leaves=783; min_data_in_leaf=448 : y = 0.887 : 39.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.0124; feature_fraction=0.412; num_leaves=234; min_data_in_leaf=1276 : y = 0.906 : 71.9 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.26; feature_fraction=0.462; num_leaves=310; min_data_in_leaf=6456 : y = 0.904 : 23.8 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.277; feature_fraction=0.901; num_leaves=1618; min_data_in_leaf=7040 : y = 0.902 : 12.4 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.0621; feature_fraction=0.959; num_leaves=679; min_data_in_leaf=5931 : y = 0.905 : 17.6 secs : initdesign\n",
      "\n",
      "[mbo] 0: learning_rate=0.151; feature_fraction=0.279; num_leaves=1416; min_data_in_leaf=3478 : y = 0.901 : 23.3 secs : initdesign\n",
      "\n",
      "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
      "\n",
      "Sat Aug 30 00:29:45 2025\n",
      "\n",
      "AUC: 0.904011366273669\n",
      "\n",
      "[mbo] 1: learning_rate=0.01; feature_fraction=0.508; num_leaves=16; min_data_in_leaf=3259 : y = 0.904 : 89.3 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:31:14 2025\n",
      "\n",
      "AUC: 0.904993908648033\n",
      "\n",
      "[mbo] 2: learning_rate=0.0101; feature_fraction=1; num_leaves=1158; min_data_in_leaf=6503 : y = 0.905 : 72.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:32:28 2025\n",
      "\n",
      "AUC: 0.901012774755335\n",
      "\n",
      "[mbo] 3: learning_rate=0.0101; feature_fraction=0.101; num_leaves=1497; min_data_in_leaf=1620 : y = 0.901 : 97.1 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:34:05 2025\n",
      "\n",
      "AUC: 0.903929333063213\n",
      "\n",
      "[mbo] 4: learning_rate=0.0531; feature_fraction=0.314; num_leaves=33; min_data_in_leaf=6472 : y = 0.904 : 29.1 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:34:35 2025\n",
      "\n",
      "AUC: 0.901788992399413\n",
      "\n",
      "[mbo] 5: learning_rate=0.0753; feature_fraction=0.707; num_leaves=1239; min_data_in_leaf=6498 : y = 0.902 : 17.9 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:34:54 2025\n",
      "\n",
      "AUC: 0.902964045787838\n",
      "\n",
      "[mbo] 6: learning_rate=0.011; feature_fraction=1; num_leaves=511; min_data_in_leaf=5340 : y = 0.903 : 46.4 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:35:41 2025\n",
      "\n",
      "AUC: 0.903741835630634\n",
      "\n",
      "[mbo] 7: learning_rate=0.0102; feature_fraction=0.97; num_leaves=2048; min_data_in_leaf=6054 : y = 0.904 : 59.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:36:41 2025\n",
      "\n",
      "AUC: 0.904401322835991\n",
      "\n",
      "[mbo] 8: learning_rate=0.0361; feature_fraction=1; num_leaves=721; min_data_in_leaf=7893 : y = 0.904 : 21.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:37:03 2025\n",
      "\n",
      "AUC: 0.906744284030541\n",
      "\n",
      "[mbo] 9: learning_rate=0.037; feature_fraction=0.894; num_leaves=8; min_data_in_leaf=1381 : y = 0.907 : 19.6 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:37:23 2025\n",
      "\n",
      "AUC: 0.905687140017128\n",
      "\n",
      "[mbo] 10: learning_rate=0.011; feature_fraction=0.998; num_leaves=9; min_data_in_leaf=1123 : y = 0.906 : 47.2 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:38:11 2025\n",
      "\n",
      "AUC: 0.906644496668787\n",
      "\n",
      "[mbo] 11: learning_rate=0.0417; feature_fraction=0.564; num_leaves=8; min_data_in_leaf=1033 : y = 0.907 : 39.6 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:38:51 2025\n",
      "\n",
      "AUC: 0.904540008104248\n",
      "\n",
      "[mbo] 12: learning_rate=0.0517; feature_fraction=0.744; num_leaves=23; min_data_in_leaf=3887 : y = 0.905 : 23.3 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:39:15 2025\n",
      "\n",
      "AUC: 0.903133605685415\n",
      "\n",
      "[mbo] 13: learning_rate=0.203; feature_fraction=0.982; num_leaves=8; min_data_in_leaf=8000 : y = 0.903 : 10.9 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:39:27 2025\n",
      "\n",
      "AUC: 0.906148152506814\n",
      "\n",
      "[mbo] 14: learning_rate=0.0421; feature_fraction=0.42; num_leaves=8; min_data_in_leaf=1793 : y = 0.906 : 32.6 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 15 in the file bayesiana.RDATA.\n",
      "\n",
      "Sat Aug 30 00:40:05 2025\n",
      "\n",
      "AUC: 0.890197965744425\n",
      "\n",
      "[mbo] 15: learning_rate=0.0377; feature_fraction=1; num_leaves=765; min_data_in_leaf=7 : y = 0.89 : 128.0 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:42:14 2025\n",
      "\n",
      "AUC: 0.902997790606512\n",
      "\n",
      "[mbo] 16: learning_rate=0.114; feature_fraction=0.919; num_leaves=268; min_data_in_leaf=6289 : y = 0.903 : 16.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:42:31 2025\n",
      "\n",
      "AUC: 0.902554957059797\n",
      "\n",
      "[mbo] 17: learning_rate=0.01; feature_fraction=0.101; num_leaves=1880; min_data_in_leaf=8000 : y = 0.903 : 124.4 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:44:36 2025\n",
      "\n",
      "AUC: 0.904929023192096\n",
      "\n",
      "[mbo] 18: learning_rate=0.0101; feature_fraction=1; num_leaves=1665; min_data_in_leaf=5475 : y = 0.905 : 58.4 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:45:35 2025\n",
      "\n",
      "AUC: 0.905814830356172\n",
      "\n",
      "[mbo] 19: learning_rate=0.0276; feature_fraction=0.522; num_leaves=8; min_data_in_leaf=1317 : y = 0.906 : 54.2 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:46:30 2025\n",
      "\n",
      "AUC: 0.905112246188208\n",
      "\n",
      "[mbo] 20: learning_rate=0.0591; feature_fraction=0.774; num_leaves=170; min_data_in_leaf=2204 : y = 0.905 : 22.7 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:46:53 2025\n",
      "\n",
      "AUC: 0.906866660798506\n",
      "\n",
      "[mbo] 21: learning_rate=0.0564; feature_fraction=0.898; num_leaves=10; min_data_in_leaf=932 : y = 0.907 : 15.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:47:10 2025\n",
      "\n",
      "AUC: 0.903068785655833\n",
      "\n",
      "[mbo] 22: learning_rate=0.234; feature_fraction=0.998; num_leaves=8; min_data_in_leaf=5179 : y = 0.903 : 11.8 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:47:22 2025\n",
      "\n",
      "AUC: 0.902829546875019\n",
      "\n",
      "[mbo] 23: learning_rate=0.01; feature_fraction=0.103; num_leaves=743; min_data_in_leaf=6475 : y = 0.903 : 114.7 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:49:18 2025\n",
      "\n",
      "AUC: 0.900515229683404\n",
      "\n",
      "[mbo] 24: learning_rate=0.0585; feature_fraction=0.965; num_leaves=103; min_data_in_leaf=1176 : y = 0.901 : 28.2 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:49:46 2025\n",
      "\n",
      "AUC: 0.902920519653996\n",
      "\n",
      "[mbo] 25: learning_rate=0.0102; feature_fraction=0.951; num_leaves=201; min_data_in_leaf=3641 : y = 0.903 : 47.5 secs : infill_ei\n",
      "\n",
      "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
      "\n",
      "Sat Aug 30 00:50:39 2025\n",
      "\n",
      "AUC: 0.905130105193833\n",
      "\n",
      "[mbo] 26: learning_rate=0.0643; feature_fraction=0.881; num_leaves=701; min_data_in_leaf=7975 : y = 0.905 : 20.5 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:51:01 2025\n",
      "\n",
      "AUC: 0.900624714187462\n",
      "\n",
      "[mbo] 27: learning_rate=0.0876; feature_fraction=0.999; num_leaves=1847; min_data_in_leaf=1315 : y = 0.901 : 25.3 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:51:27 2025\n",
      "\n",
      "AUC: 0.906160793956333\n",
      "\n",
      "[mbo] 28: learning_rate=0.0105; feature_fraction=0.589; num_leaves=638; min_data_in_leaf=7326 : y = 0.906 : 86.3 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:52:54 2025\n",
      "\n",
      "AUC: 0.903508321830069\n",
      "\n",
      "[mbo] 29: learning_rate=0.0741; feature_fraction=0.999; num_leaves=616; min_data_in_leaf=7120 : y = 0.904 : 18.0 secs : infill_ei\n",
      "\n",
      "Sat Aug 30 00:53:12 2025\n",
      "\n",
      "AUC: 0.905030196366293\n",
      "\n",
      "[mbo] 30: learning_rate=0.011; feature_fraction=0.202; num_leaves=677; min_data_in_leaf=7939 : y = 0.905 : 113.6 secs : infill_ei\n",
      "\n",
      "Saved the final state in the file bayesiana.RDATA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inicio la optimizacion bayesiana, retomando si ya existe\n",
    "\n",
    "if (!file.exists(kbayesiana)) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "aC-ls8JfNDTf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   learning_rate feature_fraction num_leaves min_data_in_leaf num_iterations\n",
      "           <num>            <num>      <int>            <int>          <int>\n",
      "1:    0.05635889        0.8975672         10              932            180\n"
     ]
    }
   ],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "tb_bayesiana[, iter:= .I]\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y, -num_iterations)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file= \"BO_log.txt\",\n",
    "  sep= \"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  list(learning_rate, feature_fraction, num_leaves, min_data_in_leaf, num_iterations)\n",
    "]\n",
    "\n",
    "print(PARAM$out$lgbm$mejores_hiperparametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5dPpsZpcX6e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Sat Aug 30 00:55:12 2025'"
      ],
      "text/latex": [
       "'Sat Aug 30 00:55:12 2025'"
      ],
      "text/markdown": [
       "'Sat Aug 30 00:55:12 2025'"
      ],
      "text/plain": [
       "[1] \"Sat Aug 30 00:55:12 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vu-1vf5LrVg"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
